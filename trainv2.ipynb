{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = img.resize((128, 128))  # Resize image to your preferred size\n",
    "    img_array = np.array(img) / 255.0  # Normalize pixel values to between 0 and 1\n",
    "    return img_array\n",
    "\n",
    "# Function to load data from directories\n",
    "def load_data(directory):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if '.jpg' != file[-4:]: continue\n",
    "            file_path = os.path.join(root, file)\n",
    "            label = os.path.basename(root)\n",
    "            data.append(load_and_preprocess_image(file_path))\n",
    "            labels.append(label)\n",
    "\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading and Processing Completed...\n"
     ]
    }
   ],
   "source": [
    "# Load data from the specified folders\n",
    "train_data_cinder, train_labels_cinder = load_data(\"cinder\")\n",
    "train_data_stripe, train_labels_stripe = load_data(\"stripe\")\n",
    "train_data_both, train_labels_both = load_data(\"both\")\n",
    "\n",
    "print(\"Data Loading and Processing Completed...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data from all folders\n",
    "train_data = np.concatenate([train_data_cinder, train_data_stripe, train_data_both])\n",
    "train_labels = np.concatenate([train_labels_cinder, train_labels_stripe, train_labels_both])\n",
    "\n",
    "# Shuffle the data\n",
    "indices = np.arange(train_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "train_data = train_data[indices]\n",
    "train_labels = train_labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Model\n",
    "# Define the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')  # 4 output classes: cinder, stripe, both, none\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "4/4 [==============================] - 4s 512ms/step - loss: 1.8909 - accuracy: 0.3737 - val_loss: 1.2303 - val_accuracy: 0.2800\n",
      "Epoch 2/15\n",
      "4/4 [==============================] - 2s 425ms/step - loss: 1.2000 - accuracy: 0.3333 - val_loss: 1.0642 - val_accuracy: 0.2800\n",
      "Epoch 3/15\n",
      "4/4 [==============================] - 2s 401ms/step - loss: 1.0975 - accuracy: 0.3535 - val_loss: 0.9316 - val_accuracy: 0.6400\n",
      "Epoch 4/15\n",
      "4/4 [==============================] - 2s 405ms/step - loss: 1.0240 - accuracy: 0.4949 - val_loss: 1.0221 - val_accuracy: 0.6400\n",
      "Epoch 5/15\n",
      "4/4 [==============================] - 2s 396ms/step - loss: 1.0054 - accuracy: 0.4949 - val_loss: 0.8655 - val_accuracy: 0.6400\n",
      "Epoch 6/15\n",
      "4/4 [==============================] - 2s 422ms/step - loss: 1.0217 - accuracy: 0.4949 - val_loss: 0.9245 - val_accuracy: 0.4400\n",
      "Epoch 7/15\n",
      "4/4 [==============================] - 2s 391ms/step - loss: 0.9618 - accuracy: 0.6364 - val_loss: 0.8788 - val_accuracy: 0.7200\n",
      "Epoch 8/15\n",
      "4/4 [==============================] - 2s 379ms/step - loss: 0.8975 - accuracy: 0.5556 - val_loss: 0.7700 - val_accuracy: 0.7200\n",
      "Epoch 9/15\n",
      "4/4 [==============================] - 2s 391ms/step - loss: 0.7654 - accuracy: 0.6667 - val_loss: 0.8137 - val_accuracy: 0.5600\n",
      "Epoch 10/15\n",
      "4/4 [==============================] - 2s 399ms/step - loss: 0.7003 - accuracy: 0.7374 - val_loss: 0.6691 - val_accuracy: 0.6800\n",
      "Epoch 11/15\n",
      "4/4 [==============================] - 2s 397ms/step - loss: 0.6207 - accuracy: 0.7576 - val_loss: 0.6552 - val_accuracy: 0.6800\n",
      "Epoch 12/15\n",
      "4/4 [==============================] - 2s 400ms/step - loss: 0.6165 - accuracy: 0.7374 - val_loss: 0.8195 - val_accuracy: 0.6800\n",
      "Epoch 13/15\n",
      "4/4 [==============================] - 2s 376ms/step - loss: 0.5840 - accuracy: 0.7273 - val_loss: 0.9805 - val_accuracy: 0.5600\n",
      "Epoch 14/15\n",
      "4/4 [==============================] - 2s 371ms/step - loss: 0.4452 - accuracy: 0.8283 - val_loss: 1.0605 - val_accuracy: 0.6000\n",
      "Epoch 15/15\n",
      "4/4 [==============================] - 2s 358ms/step - loss: 0.3626 - accuracy: 0.8485 - val_loss: 0.9283 - val_accuracy: 0.6400\n",
      "Model has completed training\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to integers\n",
    "label_mapping = {'cinder': 0, 'stripe': 1, 'both': 2, 'none': 3}\n",
    "train_labels_int = np.array([label_mapping[label] for label in train_labels])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels_int, epochs=15, validation_split=0.2)\n",
    "print(\"Model has completed training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 120ms/step - loss: 0.4275 - accuracy: 0.8306\n",
      "Model Accuracy: 0.8306451439857483\n"
     ]
    }
   ],
   "source": [
    "# Save the model accuracy using pickle\n",
    "accuracy = model.evaluate(train_data, train_labels_int)[1]\n",
    "with open('model_accuracy.pkl', 'wb') as f:\n",
    "    pickle.dump(accuracy, f)\n",
    "\n",
    "# Print the model accuracy\n",
    "print(f'Model Accuracy: {accuracy}')\n",
    "\n",
    "# Save the trained model\n",
    "model.save('kitty_classifier_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that the training is complete, we will inference the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = load_model('image_classifier_model.keras')  # Adjust the path accordingly\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def load_and_preprocess_single_image(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = img.resize((128, 128))  # Resize image to match the training size\n",
    "    img_array = np.array(img) / 255.0  # Normalize pixel values to between 0 and 1\n",
    "    return np.expand_dims(img_array, axis=0)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "The predicted class for the image is: cinder\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the new image\n",
    "image_path = 'imagec.jpg'  # Replace with your image file path\n",
    "new_image = load_and_preprocess_single_image(image_path)\n",
    "\n",
    "# Perform inference\n",
    "predictions = model.predict(new_image)\n",
    "\n",
    "# Decode the prediction\n",
    "class_labels = ['cinder', 'stripe', 'both', 'none']\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "predicted_class = class_labels[predicted_class_index]\n",
    "\n",
    "# Print the predicted class\n",
    "print(f'The predicted class for the image is: {predicted_class}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
